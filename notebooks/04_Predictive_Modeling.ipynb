{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Análise Preditiva Simplificada\n",
    "\n",
    "This notebook demonstrates a simplified machine learning process to predict exam scores, as outlined in the \"Análise Preditiva\" section of the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we saved the cleaned data, we could load it here instead:\n",
    "# df = pd.read_parquet('cleaned_student_data.parquet')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and Preprocessing\n",
    "\n",
    "Based on EDA and HTML feature importance chart, let's select features. The HTML mentions:\n",
    "`study_hours_per_day`, `attendance_percentage`, `mental_health_rating`, `sleep_hours`, `internet_quality`, `parental_education_level`.\n",
    "We'll use these and a few more common sense ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop student_id if it's still there\n",
    "if 'student_id' in df.columns:\n",
    "    df_model = df.drop('student_id', axis=1).copy()\n",
    "else:\n",
    "    df_model = df.copy()\n",
    "\n",
    "X = df_model.drop('exam_score', axis=1)\n",
    "y = df_model['exam_score']\n",
    "\n",
    "# Identify numerical and categorical features for the model\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "print(\"Numerical Features:\", numerical_features)\n",
    "print(\"Categorical Features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipelines for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', drop='first') # drop='first' to avoid multicollinearity\n",
    "\n",
    "# Create a preprocessor object using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', LinearRegression())])\n",
    "\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "y_pred_lr = lr_pipeline.predict(X_test)\n",
    "\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Linear Regression Performance:\")\n",
    "print(f\"RMSE: {rmse_lr:.2f}\")\n",
    "print(f\"R²: {r2_lr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Regressor Performance:\")\n",
    "print(f\"RMSE: {rmse_rf:.2f}\")\n",
    "print(f\"R²: {r2_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: The HTML reports RMSE of 8.52 (LR) / 6.95 (RF) and R² of 0.78 (LR) / 0.85 (RF). The actual calculated values will depend on the dataset, train/test split, and exact features used. The provided CSV is synthetic and these numbers are achievable with it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importância das Features (Exemplo do Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after one-hot encoding\n",
    "feature_names_out = rf_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "importances = rf_pipeline.named_steps['regressor'].feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names_out, 'importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Feature Importances from Random Forest:\")\n",
    "print(feature_importance_df.head(10))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance_df.head(10), palette='mako') # Top 10\n",
    "plt.title('Top 10 Feature Importances (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HTML's feature importance chart shows `study_hours_per_day` as most important, followed by `attendance_percentage`, `mental_health_rating`, etc. The actual results from the model might vary slightly in order but should generally highlight similar features as strong predictors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
